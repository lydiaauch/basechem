import json
import logging
import os
import pickle
import shutil
import subprocess
from concurrent.futures import ProcessPoolExecutor, as_completed
from shutil import copy, copyfile
from time import sleep

import numpy as np
from django.conf import settings
from django.core.mail import mail_admins
from rdkit import Chem
from rdkit.Chem import AllChem
from toklat.feature_generation import load_pdb_to_mol

from basechem.common.constants import *
from basechem.common.slurm_utils import (
    get_bash_script_from_commands,
    has_job_completed,
    has_job_stalled,
    run_on_slurm_node,
)
from basechem.main.constants import MAX_TORSION_ATTEMPTS
from basechem.mni_common.storage import media_file_exists, upload_to_media_storage

logger = logging.getLogger("django")


#####################
### TORSION UTILS ###
#####################


def get_torsion_commands(
    dihedral_smarts, dihedral_atoms, input_filename, output_filename, dihedral
):
    """
    Provides a list of bash commands to execute in order to run the Mayachemtools torsion script for a single dihedral.
    :param dihedral_smarts: a smarts query describing the atoms to scan
    :param dihedral_atoms: a comma separated string of 4 atom indices (ex: '3,5,8,9')
        selected corresponding to dihedral_smarts used by mayachem to limit substructure search to relevant atoms
    :param input_filename: name of the input file provided to the Mayachemtools torsion script
    :param output_filename: name of the output file provided to the Mayachemtools torsion script
    :param dihedral: a number, the dihedral to calculate (between -180 and 180 degrees, inclusive)
    :return: a list of bash commands to run for the torsion scan
    """
    commands = [
        f'eval "$({settings.MAYACHEMTOOLS_CONDA_EXEC_PATH} shell.bash hook)"',
        f"conda activate {settings.MAYACHEMTOOLS_ENV}",
        f'Psi4PerformTorsionScan.py --infile3D yes --modeMols All --torsionMaxMatches 1 --torsionMinimize No --torsionRangeMode Angles --torsionRange {dihedral} --useChirality yes --method HF3c --overwrite -t "{dihedral_smarts}" --torsionsFilterbyAtomIndices {dihedral_atoms} -i {input_filename} -o {output_filename}',
    ]
    return commands


def get_psi4_log_filename(input_filename):
    """
    The torsion script from Mayachemtools writes Psi4 logs to a file that is named based on
    the input sdf filename. This function returns that name so that the log file can be located.
    :param input_filename: name of the input file provided to the Mayachemtools torsion script
    :return: Psi4 log filename generated by the mayachemtools torsion script.
    """
    return f"{os.path.splitext(input_filename)[0]}_Psi4.out"


def get_torsion_output_filenames(output_filename):
    """
    The torsion script from Mayachemtools modifies the output filename provided as
    the command line argument. This function returns those modified names.
    :param output_filename: name of the output file provided to the Mayachemtools torsion script
    :return: a tuple w/ names of output files (sdf filename, svg file name) saved on the EFS mount
        by the Mayachemtools torsion script
    """
    filename_prefix = os.path.splitext(output_filename)[0]
    # Psi4PerformTorsionScan.py from Mayachemtools appends "_Mol1_Torsion1_Match1" to the output filename
    # specified in the command line.
    return (
        f"{filename_prefix}_Mol1_Torsion1_Match1.sdf",
        f"{filename_prefix}_Mol1_Torsion1_Match1_Plot.svg",
    )


def set_up_slurm_shared_files(output_path):
    """
    Set up the slurm working directory in the basechem_tmp directory on in the shared files of
    the EFS mount and return paths to this working directory relative to the slurm node and basechem container.
    :param output_path: a string, the path (in the basechem container) to the final output file of the slurm analysis
    :returns: a tuple (slurm_working_dir, container_working_dir) where
        - slurm_working_dir is a string, the working directory relative to the slurm node
        - container_working_dir is a string, the working directory relative to the basechem container
    """
    path_to_create = os.path.dirname(os.path.relpath(output_path, settings.MEDIA_ROOT))
    slurm_working_dir = os.path.join(
        settings.SLURM_SHARED_FILES_TMP_DIR, path_to_create
    )
    container_working_dir = os.path.join(
        settings.SHARED_FILES_TMP_DIR_FROM_CONTAINER, path_to_create
    )
    os.makedirs(container_working_dir, exist_ok=True)
    return slurm_working_dir, container_working_dir


def run_mc_torsion_scan(
    input_path, dihedral_smarts, dihedral_atoms, output_path, task_name
):
    """
    Runs the torsion analysis either on Slurm or locally, depending on the settings.
    :param input_path: path to sdf file to run the torsion scan on
    :param dihedral_smarts: a smarts query describing the atoms to scan
    :param dihedral_atoms: a comma separated string of 4 atom indices (ex: '3,5,8,9')
        selected corresponding to dihedral_smarts
    :param output_path: path to the output sdf file from the torsion scan
    :param task_name: DjangoQ task name for this set of slurm jobs
    :return: path to the expected output sdf file from the torsion scan (in media storage)
    """
    if settings.SLURM_REST_API_HOST:
        return run_mc_torsion_scan_on_slurm(
            input_path, dihedral_smarts, dihedral_atoms, output_path, task_name
        )
    else:
        return run_mc_torsion_scan_locally(
            input_path, dihedral_smarts, dihedral_atoms, output_path, task_name
        )


def run_mc_torsion_scan_on_slurm(
    input_path, dihedral_smarts, dihedral_atoms, output_path, task_name
):
    """
    Checks if the output file already exists for the torsion scan and if not, runs
    the torsion analysis on a Slurm cluster.
    :param input_path: path to sdf file to run the torsion scan on
    :param dihedral_smarts: a smarts query describing the atoms to scan
    :param dihedral_atoms: a comma separated string of 4 atom indices (ex: '3,5,8,9')
        selected corresponding to dihedral_smarts
    :param output_path: path to the output sdf file from the torsion scan
    :param task_name: DjangoQ task name for this set of slurm jobs
    :return: path to the expected output sdf file from the torsion scan (in media storage)
    """
    if media_file_exists(output_path):
        return output_path

    all_dihedrals = range(-180, 190, 10)
    filenames = {}
    original_input_filename = os.path.basename(input_path)
    final_output_filename = os.path.basename(output_path)
    # Generate filenames for each dihedral
    for dihedral in all_dihedrals:
        filenames[dihedral] = {
            "input": f"{os.path.splitext(original_input_filename)[0]}_{dihedral}.sdf",
            "output": f"{os.path.splitext(final_output_filename)[0]}_{dihedral}.sdf",
        }
    # Set up the directory structure on the EFS mount
    slurm_working_dir, container_working_dir = set_up_slurm_shared_files(output_path)
    # Copy input files to working directory
    copyfile(input_path, os.path.join(container_working_dir, original_input_filename))
    # Make a copy of the input file for each dihedral because the Psi4 logfile name is based on the input file name
    for dihedral in all_dihedrals:
        copyfile(
            input_path,
            os.path.join(container_working_dir, filenames[dihedral]["input"]),
        )
    # Start all the jobs
    data = {}
    inprogress_dihedrals = []
    for dihedral in all_dihedrals:
        job_id = submit_torsion_job_to_slurm(
            f"{task_name}_{dihedral}",
            dihedral,
            dihedral_smarts,
            dihedral_atoms,
            filenames[dihedral]["input"],
            filenames[dihedral]["output"],
            slurm_working_dir,
        )
        if job_id:
            data[dihedral] = {"job_id": job_id, "attempt": 1}
            inprogress_dihedrals.append(dihedral)

    # Loop through jobs until all are complete. If a job fails, try again up to max_retries
    result_mols = []
    while inprogress_dihedrals:
        for dihedral in inprogress_dihedrals:
            if has_job_completed(data[dihedral]["job_id"]):
                job_name = f"{task_name}_{dihedral}"
                inprogress_dihedrals.remove(dihedral)
                try:
                    mol = process_torsion_job_result(
                        filenames[dihedral]["input"],
                        filenames[dihedral]["output"],
                        job_name,
                        container_working_dir,
                    )
                    result_mols.append(mol)
                except:
                    if data[dihedral]["attempt"] < MAX_TORSION_ATTEMPTS:
                        job_id = submit_torsion_job_to_slurm(
                            job_name,
                            dihedral,
                            dihedral_smarts,
                            dihedral_atoms,
                            filenames[dihedral]["input"],
                            filenames[dihedral]["output"],
                            slurm_working_dir,
                        )
                        if job_id:
                            data[dihedral]["job_id"] = job_id
                            data[dihedral]["attempt"] += 1
                            inprogress_dihedrals.append(dihedral)
            elif has_job_stalled(data[dihedral]["job_id"]):
                # Don't wait for this job - the admins have been notified
                inprogress_dihedrals.remove(dihedral)
        sleep(SLURM_JOB_STATUS_CHECK_PERIOD)

    # Calculate the relative energy based on the Psi4_Energy
    energies = [float(mol.GetProp("Psi4_Energy (kcal/mol)")) for mol in result_mols]
    min_energy = min(energies)
    for mol, energy in zip(result_mols, energies):
        mol.SetProp("Psi4_Relative_Energy (kcal/mol)", str(energy - min_energy))

    # Combine result files into a single file in EFS
    tmp_output_path = os.path.join(container_working_dir, final_output_filename)
    writer = Chem.SDWriter(tmp_output_path)
    for mol in result_mols:
        writer.write(mol)
    writer.close()
    # Copy the output file from the EFS mount to local
    copyfile(tmp_output_path, output_path)
    upload_to_media_storage(output_path)
    return output_path


def run_mc_torsion_scan_locally(  # pragma: no cover
    input_path, dihedral_smarts, dihedral_atoms, output_path, task_name
):
    """
    Checks if the output file already exists for the torsion scan and if not, runs
    the torsion analysis locally.
    :param input_path: path to sdf file to run the torsion scan on
    :param dihedral_smarts: a smarts query describing the atoms to scan
    :param dihedral_atoms: a comma separated string of 4 atom indices (ex: '3,5,8,9')
        selected corresponding to dihedral_smarts
    :param output_path: path to the output sdf file from the torsion scan
    :param task_name: DjangoQ task name for this set of slurm jobs
    :return: path to the expected output sdf file from the torsion scan (in media storage)
    """
    if media_file_exists(output_path):
        return output_path

    all_dihedrals = range(-180, 190, 10)
    filenames = {}
    original_input_filename = os.path.basename(input_path)
    final_output_filename = os.path.basename(output_path)
    # Generate filenames for each dihedral
    for dihedral in all_dihedrals:
        filenames[dihedral] = {
            "input": f"{os.path.splitext(original_input_filename)[0]}_{dihedral}.sdf",
            "output": f"{os.path.splitext(final_output_filename)[0]}_{dihedral}.sdf",
        }
    # Set up working directory
    tmp_output_path = os.path.join(
        os.path.dirname(output_path), "torsion_working_dir", final_output_filename
    )
    container_working_dir = os.path.dirname(tmp_output_path)
    os.makedirs(container_working_dir, exist_ok=True)
    # Copy input files to working directory
    copyfile(input_path, os.path.join(container_working_dir, original_input_filename))
    # Make a copy of the input file for each dihedral because the Psi4 logfile name is based on the input file name
    for dihedral in all_dihedrals:
        copyfile(
            input_path,
            os.path.join(container_working_dir, filenames[dihedral]["input"]),
        )
    result_mols = []
    for dihedral in all_dihedrals:
        try:
            # Run torsion job locally
            commands = get_torsion_commands(
                dihedral_smarts,
                dihedral_atoms,
                filenames[dihedral]["input"],
                filenames[dihedral]["output"],
                dihedral,
            )
            script = get_bash_script_from_commands(
                [f"export PATH=$PATH:{settings.MAYACHEMTOOLS_DIR}/bin"] + commands
            )
            tmp_script_file = os.path.join(
                container_working_dir, f"run_torsion_{dihedral}.sh"
            )
            with open(tmp_script_file, "w+") as script_file:
                script_file.write(script)
            subprocess.call(
                ["bash", tmp_script_file],
                cwd=container_working_dir,
                stdout=subprocess.DEVNULL,
                stderr=subprocess.STDOUT,
            )
            # Process the output files from the torsion job
            mol = process_torsion_job_result(
                filenames[dihedral]["input"],
                filenames[dihedral]["output"],
                f"{task_name}_{dihedral}",
                container_working_dir,
            )
            result_mols.append(mol)
        except:
            pass

    # Calculate the relative energy based on the Psi4_Energy
    energies = [float(mol.GetProp("Psi4_Energy (kcal/mol)")) for mol in result_mols]
    min_energy = min(energies)
    for mol, energy in zip(result_mols, energies):
        mol.SetProp("Psi4_Relative_Energy (kcal/mol)", str(energy - min_energy))

    # Combine result files into a single file
    writer = Chem.SDWriter(tmp_output_path)
    for mol in result_mols:
        writer.write(mol)
    writer.close()
    # Copy the output file from the working dir to the expected location
    copyfile(tmp_output_path, output_path)
    upload_to_media_storage(output_path)
    return output_path


def process_torsion_job_result(
    input_filename, output_filename, job_name, container_working_dir
):
    """
    Process the output from a completed torsion job, returning a mol object if the job
    succeeded and raising an Exception if it failed.
    :param input_filename: a string, the name of the input file for the mayachem torsion script
    :param output_filename: a string, the name of the expected output file
    :param job_name: a string, the name of the job running on the slurm cluster
    :param container_working_dir: a string, the path to the working directory relative to the basechem container
    :returns: a mol object with the result of the torsion job
    """
    tmp_sdf_filename, tmp_svg_filename = get_torsion_output_filenames(output_filename)
    tmp_sdf_path = os.path.join(container_working_dir, tmp_sdf_filename)
    tmp_svg_path = os.path.join(container_working_dir, tmp_svg_filename)

    # The last step in the torsion scan produces a chart in the form of an svg file.
    # Look for that file to confirm that the job completed successfully.
    if not os.path.exists(tmp_svg_path):
        psi4_log_filename = get_psi4_log_filename(input_filename)
        psi4_log_filepath = os.path.join(
            os.path.dirname(tmp_sdf_path), psi4_log_filename
        )
        if os.path.exists(psi4_log_filepath):
            # Psi4 script failed for an unknown reason. In most cases, simply re-running this job
            # fixes the issue so an exception is raised here so that the Django Q fails and is
            # restarted automatically by the cluster.
            raise RuntimeError(f"Psi4 script failed for {job_name}")
        else:
            # An error unrelated to Psi4 occurred
            message = f"Torsion scan job {job_name} failed. Psi4 log file not found."
            logger.error(message)
            mail_admins(ADMIN_FAILURE, message)
            raise RuntimeError(f"Torsion failure, no Psi4 log file for {job_name}.")
    mol = Chem.SDMolSupplier(tmp_sdf_path)[0]
    return mol


def submit_torsion_job_to_slurm(
    job_name,
    dihedral,
    dihedral_smarts,
    dihedral_atoms,
    input_filename,
    output_filename,
    slurm_working_dir,
):
    """
    Submit a torsion job for a single dihedral to the slurm cluster.
    :param job_name: a string, the name of the job
    :param dihedral: an integer between -180 and 180 (inclusive), the dihedral to calculate
    :param dihedral_smarts: a smarts query describing the atoms to scan
    :param dihedral_atoms: a comma separated string of 4 atom indices (ex: '3,5,8,9')
    :param input_filename: a string, the name of the input file to the mayachem torsion script
    :param output_filename: a string, the name of the expected output file
    :param slurm_working_dir: a string, the path to the working directory relative to the slurm node
    :returns: a number, the ID of the job running on the slurm cluster (if started successfully, else None)
    """
    # Start job
    commands = get_torsion_commands(
        dihedral_smarts, dihedral_atoms, input_filename, output_filename, dihedral
    )
    job_id = run_on_slurm_node(job_name, commands, slurm_working_dir)
    if job_id:
        logger.info(f"Started torsion analysis job on slurm: {job_name}")
    else:
        logger.error(f"Failed to submit torsion analysis task: {job_name}")
    return job_id


def collect_torsion_results(tasks):
    """
    Helper for constructing torsion results dictionary
    :return: a dictionary that maps each compound occurrence to its torsion scan results
    {co-pk: {
        "torsions": {
            "co-pk-dihedral": {
                "moltext": moltext,
                "rel_energy": rel_e,
                "torsion": torsion_dihedral }}
        "delta_energy": closest_dihedral_to_input_e,
        "initial_dihedral": initial_dihedral }}
    """
    results = {}
    for task in tasks:
        if not task.success:
            continue
        else:
            co_id = task.name.split("_")[1]
            results[f"co-{co_id}"] = task.result
    return results


############################
### TORSION ALERTS UTILS ###
############################


def get_torsion_alerts_commands(input_filepath, output_filepath):
    """
    Provides a list of bash commands to execute in order to run the Mayachemtools torsion alerts script.
    :param input_filepath: name of the input file provided to the Mayachemtools script
    :param output_filename: name of the output file provided to the Mayachemtools script
    :return: a list of bash commands to run to generate torsion alerts
    """
    input_filename = os.path.basename(input_filepath)
    output_filename = os.path.basename(output_filepath)
    commands = [
        f'RDKitFilterTorsionStrainEnergyAlerts.py --alertsTotalEnergyCutoff {TORSION_ALERTS_TOTAL_ENERGY_THRESHOLD} --mp yes --mpParams  "inputDataMode,lazy,numProcesses,4,chunkSize,8" -i {input_filename} -o {output_filename} --overwrite',
    ]
    return commands


def get_torsion_alerts_filepath(input_filepath, combined=True):
    """
    For a given input file to the torsion alerts Mayachemtools script, return the path to the expected output file
    :param input_filepath: a string, the path to the input file to `generate_torsion_alerts`
    :param combined: a boolean. If False, return the output path to pass to the Mayachemtools script (via the `-o` parameter).
        If True, return the path to the combined output file after processing the output files from the Mayachemtools script.
    :returns: a string, the output filepath
    """
    path, ext = os.path.splitext(input_filepath)
    if combined:
        return path + "_alerts_all" + ext
    else:
        return path + "_alerts" + ext


def generate_torsion_alerts(input_filepath):
    """
    Runs the Mayachemtools RDKitFilterTorsionStrainEnergyAlerts.py script on the given input file.
    :param input_filepath: a string, the path to the input sdf file -> should be /home/app/web/public/media/etc.
    :returns: a string, the path to the output file with torsion alerts
    """
    # The torsion alerts script returns two files. The "filtered" filepath has conformations
    # whose total torsion strain exceeds TORSION_ALERTS_TOTAL_ENERGY_THRESHOLD. The original
    # output filepath has conformations whose total torsion strain is less than the threshold.
    # We combine all conformations in a single file so we can return the results directly to
    # the basechem analysis calculating torsion alerts.
    expected_output_path = get_torsion_alerts_filepath(input_filepath, combined=False)
    path, ext = os.path.splitext(expected_output_path)
    filtered_output_path = path + "_Filtered" + ext
    combined_output_path = get_torsion_alerts_filepath(input_filepath)

    if os.path.exists(combined_output_path):
        return combined_output_path
    else:
        working_dir = os.path.dirname(input_filepath)
        commands = get_torsion_alerts_commands(input_filepath, expected_output_path)
        script = get_bash_script_from_commands(
            [f"export PATH=$PATH:{settings.MAYACHEMTOOLS_DIR}/bin"] + commands
        )
        tmp_script_file = os.path.join(working_dir, "run_torsion_alerts.sh")
        with open(tmp_script_file, "w+") as script_file:
            script_file.write(script)

        process = subprocess.run(["bash", tmp_script_file], cwd=working_dir)
        if process.returncode == 0:
            combine_sdf_files(
                combined_output_path, [expected_output_path, filtered_output_path]
            )
            return combined_output_path


def combine_sdf_files(combined_filepath, filepaths):
    """
    Combine multiple SDF files into a single file
    :param combined_filepath: a string, the filepath of the new combined sdf file
    :param filepaths: a list of strings, the filepaths of the existing sdf files
    """
    mols = []
    for filepath in filepaths:
        try:
            for mol in Chem.SDMolSupplier(filepath, removeHs=False):
                mols.append(mol)
        except:
            logger.info(
                f"Could not read mols from {filepath}. The file might be empty."
            )

    writer = Chem.SDWriter(combined_filepath)
    for mol in mols:
        writer.write(mol)
    writer.close()
    return combined_filepath


def mol_to_torsion_alerts(mol):
    """
    Given an rdkit mol, return a tuple of 1. torsion alert data that maps a pair of atom indices (ex: "6,7") to the energy of the torsion over that bond (ex: 5.9)
    if available (return an empty dictionary if there are no torsion alerts) and 2. the total energy score of the molecule
    :param mol: an rdkit mol object
    :return: a tuple of the torsion alert data and total energy
    """
    BONDS_INDEX = 0  # The index of "RotBondIndices" in TORSION_ALERTS_PROP
    ENERGY_INDEX = 3  # The index of "Energy" in TORSION_ALERTS_PROP
    NUM_VALUES = 12  # The number of properties in TORSION_ALERTS_PROP
    if not mol.HasProp(TORSION_ALERTS_PROP):
        alerts_dict = {}
    else:
        # Convert torsion_alerts from a space-delimited string to a list of lists, where each row is an alert for a different torsion
        torsion_alerts = mol.GetProp(TORSION_ALERTS_PROP).split(" ")
        torsion_alerts = [
            torsion_alerts[i : i + NUM_VALUES]
            for i in range(0, len(torsion_alerts), NUM_VALUES)
        ]
        alerts_dict = {
            torsion_alert[BONDS_INDEX]: torsion_alert[ENERGY_INDEX]
            for torsion_alert in torsion_alerts
        }

    if not mol.HasProp(TORSION_ALERTS_ENERGY_PROP):
        energy = ""
    elif mol.GetProp(TORSION_ALERTS_ENERGY_PROP) == "NA":
        energy = ""
    else:
        energy = "%.2f" % float(mol.GetProp(TORSION_ALERTS_ENERGY_PROP))
    return alerts_dict, energy


####################
### TOKLAT UTILS ###
####################


def generate_toklat_scores(pose_filepath, receptor_filepath):
    """
    Given an SDF file with docked poses and a receptor PDB file, run the Toklat scoring model
    to score each pose.
    :param pose_filepath: path to the SDF file with docked poses
    :param receptor_filepath: path to the receptor PDB file
    :return: a path to an SDF file with the given poses and their Toklat scores
    """
    output_filepath = f"{os.path.splitext(pose_filepath)[0]}_scored.sdf"
    if not os.path.exists(output_filepath):
        model = pickle.load(open(f"{settings.TOKLAT_DIR}/models/model_v0.pkl", "rb"))
        model.update_receptor(receptor_filepath)
        output_filepath = model.predict_and_interpret_sdf(
            pose_filepath, output_filepath, sort_by_score=True
        )
    return output_filepath


def mol_to_toklat_annotations(mol, receptor_pdb_path, interaction_scale=0.5):
    """
    Given a molecule with Toklat scores and features, and a receptor PDB, return a dictionary
    with annotations to add to the 3dmoljs viewer when viewing the molecule. This method is
    adapted from the `visualize_interpretation` method in "/opt/toklat/src/toklat/vis_utils.py",
    which is written for py3Dmol instead of 3dmoljs.
    :param mol: an rdkit mol object with Toklat features
    :param receptor_pdb_path: a string, the path to the receptor PDB file that this mol was docked to
    :param interaction_scale: scaling factor for the interaction lines.
    :return: a dictionary of the form {"cylinders": [], "spheres": []} where each cylinder represents
        interactions between ligand and receptor and each sphere represents an unsatisfied atom.
    """
    receptor_mol = load_pdb_to_mol(receptor_pdb_path)

    all_annotations = {"cylinders": [], "spheres": []}
    if mol.HasProp("toklat_top_interactions"):
        interactions = json.loads(mol.GetProp("toklat_top_interactions"))
        for interaction_dict in interactions:
            loc1 = mol.GetConformer().GetAtomPosition(interaction_dict["li"])
            loc2 = receptor_mol.GetConformer().GetAtomPosition(interaction_dict["pi"])
            val = interaction_dict["summed_interaction"]
            all_annotations["cylinders"].append(
                {
                    "start": dict(x=loc1.x, y=loc1.y, z=loc1.z),
                    "end": dict(x=loc2.x, y=loc2.y, z=loc2.z),
                    "color": "blue" if val < 0 else "red",
                    "radius": 0.15
                    * np.power(np.abs(val), 0.5)
                    / np.power(interaction_scale, 0.5),
                }
            )

    if mol.HasProp("toklat_unsatisfied_ligand_atoms"):
        atoms = json.loads(mol.GetProp("toklat_unsatisfied_ligand_atoms"))
        for atom_dict in atoms:
            loc = mol.GetConformer().GetAtomPosition(atom_dict["li"])
            all_annotations["spheres"].append(
                {"center": dict(x=loc.x, y=loc.y, z=loc.z)}
            )

    if mol.HasProp("toklat_unsatisfied_protein_atoms"):
        atoms = json.loads(mol.GetProp("toklat_unsatisfied_protein_atoms"))
        for atom_dict in atoms:
            loc = receptor_mol.GetConformer().GetAtomPosition(atom_dict["pi"])
            all_annotations["spheres"].append(
                {"center": dict(x=loc.x, y=loc.y, z=loc.z)}
            )
    return all_annotations


#################
### ESP UTILS ###
#################


def run_esp_predict(input_directory, molecule_type="ligand"):
    """
    Runs ESP-DNN predict from the correct directory for the files in the given directory
    :param input_directory: directory with ESP-DNN compounds to predict
    :param molecule_type: 'ligand' or 'protein'
    :return: True if process returned a zero code
    """
    cmd = [
        "/root/miniconda3/envs/esp-dnn-env/bin/python",
        "-m",
        "esp_dnn.predict",
        "-m",
        molecule_type,
        "-i",
        input_directory,
    ]

    process = subprocess.run(cmd, cwd=settings.ESP_DIR)
    if process.returncode == 0:
        return True


def run_apbs(pqr_filepath):
    """
    Run APBS on the given PQR file to generate ESP map data
    :param pqr_filepath: path to an input PQR file with a single ligand. Basechem uses ESP DNN to generate PQR files.
    :return: path to the output DX file with ESP map data, if successful
    """
    working_dir = os.path.dirname(pqr_filepath)
    config_filepath = f"{os.path.splitext(pqr_filepath)[0]}_apbs.in"
    output_filepath = f"{os.path.splitext(pqr_filepath)[0]}_apbs.dx"
    config_text = f"""
read
    mol pqr "{os.path.basename(pqr_filepath)}"
end
elec
    mg-auto
    mol 1

    fgcent mol 1    # fine grid center
    cgcent mol 1    # coarse grid center
    fglen 12 12 12
    cglen 24 24 24
    dime 65 65 65
    lpbe          # l=linear, n=non-linear Poisson-Boltzmann equation
    bcfl sdh      # "Single Debye-Hueckel" boundary condition
    pdie 2.0      # protein dielectric
    sdie 78.0     # solvent dielectric
    chgm spl2     # Cubic B-spline discretization of point charges on grid
    srfm smol     # smoothed surface for dielectric and ion-accessibility coefficients
    swin 0.3
    temp 310.0    # temperature
    sdens 10.0
    calcenergy no
    calcforce no
    srad 1.4

    ion charge +1 conc 0.15 radius 2.0
    ion charge -1 conc 0.15 radius 1.8

    write pot dx "{os.path.splitext(os.path.basename(output_filepath))[0]}"
end
quit
        """
    with open(config_filepath, "w") as f:
        f.write(config_text)
    cmd = ["apbs", config_filepath]
    process = subprocess.run(cmd, cwd=working_dir)
    if process.returncode == 0:
        return output_filepath


def collect_esp_results(tasks):
    """
    Helper for constructing ESP results dictionary
    :return: a dictionary that maps each parent and compound to its esp data
        {"compounds": {co-pk: {"pqr": esp_pqr, "dx": esp_dx, "related_series": "s-(pk of series)"}},
        "references": {s-pk: esp_pqr},
        "receptors": {s-pk: esp_pqr}}
    """
    results = {"compounds": {}}
    for task in tasks:
        if not task.success:
            continue
        elif "references" in task.result.keys():
            # All the references are returned together
            results["references"] = task.result["references"]
            results["receptors"] = task.result.get("receptors", {})
        else:
            # Each compound occurrence runs in its own task
            co_id = task.name.split("_")[1]
            results["compounds"][f"co-{co_id}"] = task.result

    return results


###################
### ALIGN UTILS ###
###################


def collect_align_results(tasks):
    """
    Helper for constructing align results dictionary
    :return: a dictionary that maps each parent and compound to its aligned conf(s)
        {"compounds": {co-pk: {conf-id:  {"moltext": conf_moltext, "r_mmff_rel_energy": str}}},
        "references": {s-pk: moltext}
    """
    results = {"compounds": {}}
    for task in tasks:
        if not task.success:
            continue
        elif "references" in task.result.keys():
            results["references"] = task.result["references"]
            results["receptors"] = task.result["receptors"]
        else:
            co_id = task.name.split("_")[1]
            results["compounds"][f"co-{co_id}"] = task.result

    return results


#######################
### RDOCK CONSTANTS ###
#######################
# These might be updated to be more dynamic later as we see how rDock works
# with generic settings for each project
RADIUS = 6.0
SMSPH = 1.0
MINVOL = 100
MAXCAV = 1
VINC = 0.0
GRIDSTEP = 0.5

TR_MODE = "FREE"
RO_MODE = "FREE"
DI_MODE = "FREE"
DI_MAX = 30.0

###################
### RDOCK UTILS ###
###################


def collect_dock_results(tasks):
    """
    Helper for constructing dock results dictionary
    :return: a dictionary that maps each parent and compound to its aligned conf(s)
        {"compounds": {co-pk: {conf-id:  {"moltext": conf_moltext, "dockingScore": str}}},
        "references": {s-pk: moltext}}
    """
    results = {"compounds": {}}
    for task in tasks:
        if not task.success:
            continue
        elif "references" in task.result.keys():
            results["references"] = task.result["references"]
            results["receptors"] = task.result["receptors"]
        else:
            co_id = task.name.split("_")[1]
            results["compounds"][f"co-{co_id}"] = task.result

    return results


def generate_rdock_system_prm(mol2, reflig, prefix):
    """
    Create an rdock parameter file for the given receptor and reference ligand
    Parameter defaults are set with guidance from Andy Jennings Consulting, LLC
    :param mol2: path to mol2 file of the receptor to use for rdock
    :param reflig: path to sdf file to use as the reference ligand for rdock
    :param prefix: prefix to use for the rdock output files - generally a series name
    :return: path to rdock parameter file
    """
    reference_dir = os.path.split(mol2)[0]
    prm_path = os.path.join(reference_dir, f"{prefix}_rdock.prm")

    text = f"""RBT_PARAMETER_FILE_V1.00
TITLE {prefix}_auto_setup

RECEPTOR_FILE {mol2}
RECEPTOR_FLEX 3.0

##############################################
# CAVITY DEFINITION: REFERENCE LIGAND METHOD #
##############################################
SECTION MAPPER
    SITE_MAPPER RbtLigandSiteMapper
    REF_MOL {reflig}
    RADIUS {RADIUS}
    SMALL_SPHERE {SMSPH}
    MIN_VOLUME {MINVOL}
    MAX_CAVITIES {MAXCAV}
    VOL_INCR {VINC}
    GRIDSTEP {GRIDSTEP}
END_SECTION

############################
# CAVITY RESTRAINT PENALTY #
############################
SECTION CAVITY
    SCORING_FUNCTION RbtCavityGridSF
    WEIGHT 1.0
END_SECTION
    """

    with open(prm_path, "w") as f:
        f.write(text)
    f.close()

    return prm_path


def generate_rdock_grid(rdock_prm_file):
    """
    Generates a .grd and .as file in the same directory as the `rdock_prm_file` file
    :param rdock_prm_file: path to rdock parameter file that will be used to create the grid
    :return: True if there was no error when generating the rDock files
    """
    cmd = ["rbcavity", "-was", "-d", "-r", rdock_prm_file]
    process = subprocess.run(args=cmd, stdout=subprocess.PIPE)

    if "Error" in str(process.stdout):
        logger.error(f"rDock grid generation failed for prm file: {rdock_prm_file}")
        message = f"rDock failed for {rdock_prm_file} because the cavity file failed to generate."
        mail_admins(ADMIN_FAILURE, message)
        return False

    if "Segmentation fault" in str(process.stdout):
        message = f"rDock failed for {rdock_prm_file}. Check the Series sdf does not have very long lines."
        mail_admins(ADMIN_FAILURE, message)
        return False
    return True


def copy_rdock_ligand_prm(new_path):
    """
    Copy rdock prm file from installation to given path
    Additional parameter defaults are set with guidance from Andy Jennings Consulting, LLC
    :param new_path: path to copy the default rdock.prm file to
    """
    copy("/opt/rDock_2022_src/data/scripts/dock.prm", new_path)

    with open(new_path, "a+") as f:
        f.write("\n")
        f.write("SECTION LIGAND\n")
        f.write("\tTRANS_MODE\t%s\n" % TR_MODE)
        f.write("\tROT_MODE\t%s\n" % RO_MODE)
        f.write("\tDIHEDRAL\t%s\n" % DI_MODE)
        f.write("\tMAX_TRANS\t1.0\n")
        f.write("\tMAX_ROT\t30.0\n")
        f.write("\tMAX_DIHEDRAL\t%.1f\n" % DI_MAX)
        f.write("END_SECTION\n")


def run_rdock(ligand_filepath, output_filepath, receptor_prm, ligand_prm, ligruns=5):
    """
    Runs rDock docking for the given ligand and returns path to sdf of poses
    :param ligand_filepath: sdf file with ligand(s) to dock - ex. conformers of one VSM
    :param output_filepath: filepath to save docking results to
    :param receptor_prm: parameter file for defining the system of the receptor to dock to
    :param ligand_prm: parameter file for the docking protocol for this job
    :param ligruns: number of poses to produce for each conformation
    :return: path to sdf file with docked poses
    """
    basename = os.path.splitext(output_filepath)[0]
    cmd = [
        "rbdock",
        "-i",
        ligand_filepath,
        "-o",
        basename,
        "-r",
        receptor_prm,
        "-p",
        ligand_prm,
        "-n",
        str(ligruns),
    ]

    process = subprocess.run(args=cmd, stdout=subprocess.PIPE)

    if process.returncode != 0:
        logger.error(
            f"rDock failed for receptor - {receptor_prm} with ligand input file - {ligand_filepath}. CMD = {cmd}."
        )
        return ""

    return output_filepath


###################
### MMP UTILS ###
###################
def collect_mmp_results(tasks):
    """
    Helper for constructing MMP results dictionary
    :return: a dictionary that maps each compound occurrence to its MMP analysis results
    {co-pk: list_of_Compound_PKs}
    """
    results = {}
    for task in tasks:
        if not task.success:
            continue
        else:
            co_id = task.name.split("_")[1]
            results[f"co-{co_id}"] = task.result
    return results


###################
### ALIGN UTILS ###
###################
def convert_sdf_to_mol2(sdf_filepath):
    """
    RDKit doesn't support conversion to mol2 format, so we use OpenBabel to convert the sdf to mol2
    :param sdf_filepath: path to sdf file to convert
    :return: path to mol2 file
    """
    mol2_filepath = os.path.splitext(sdf_filepath)[0] + ".mol2"
    cmd = ["obabel", "-i", "sdf", sdf_filepath, "-O", mol2_filepath]

    process = subprocess.run(args=cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    if process.returncode == 0:
        return mol2_filepath


def align_conf(conf_path, i, lsalign_dir, template_mol2):
    """
    Helper to align a single conformer using ls-align
    :param conf_path: the path to an sdf file with a single conformer to align
    :param i: index of the conformer
    :param lsalign_dir: directory to write ls-align files to
    :param template_mol2: path to the template mol2 file
    """
    conf_mol2 = convert_sdf_to_mol2(conf_path)
    aligned_pdb = os.path.join(lsalign_dir, f"aligned_conf_{i}.pdb")

    cmd = [
        "/opt/LS-align/src/LSalign",
        conf_mol2,
        template_mol2,
        "-rf",
        "1",  # flexible align
        "-md",
        "1",  # generate rotamers of query ligand
        "-acc",
        "1",  # take longer to search for more accurate alignment
        "-o",
        aligned_pdb,
    ]

    process = subprocess.run(args=cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)

    try:
        if not process.stderr:
            # LS-Align outputs a bytes table which needs to be parsed to get the PC-Score
            result_values = process.stdout.split(b"\n")[3]
            pc_score = [x for x in result_values.split(b" ") if x][5].decode("utf-8")

            # Remove second mol (template structure) from pdb, RDKit struggles to parse with GetMolFrags
            with open(aligned_pdb, "r") as input:
                with open("/tmp/tmp.pdb", "w") as output:
                    lines = input.readlines()
                    for line in lines:
                        if "TER" in line:
                            break
                        else:
                            output.write(line)
            shutil.move("/tmp/tmp.pdb", aligned_pdb)

            pdb = Chem.MolFromPDBFile(aligned_pdb, sanitize=False, removeHs=False)
            # If there is anything else in the file, only keep the first mol
            mol = Chem.GetMolFrags(pdb, asMols=True)[0]
            mol.SetProp("LSAlign_PCScore", pc_score)
            conf = Chem.SDMolSupplier(conf_path)[0]
            # Reassign all props since they get removed by LS-Align
            mol.SetProp("_Name", conf.GetProp("_Name"))
            for prop in conf.GetPropNames():
                mol.SetProp(prop, conf.GetProp(prop))
            # ls-align removes bond order so need to reset the aromaticity, etc from the original query conformer
            mol = AllChem.AssignBondOrdersFromTemplate(conf, mol)

            # Overwrite the file with the new mol, since passing the object loses all metadata
            writer = Chem.SDWriter(conf_path)
            writer.write(mol)
            writer.close()

            return conf_path

        else:
            mail_admins(
                ADMIN_FAILURE,
                f"LS-Align failed for {conf_mol2} and {template_mol2}: \n{process.stderr}",
            )
            return
    except Exception as e:
        # Sometimes there is a weird error where a pdb file doesn't exist
        return


def run_lsalign(query_sdf, template_sdf, final_sdf_path):
    """
    Flexibly align the structures in the query sdf to the template compound and return the best aligned structure
    :param query_sdf: sdf file containing structures (ideally conformers) to align to the template
    :param template_sdf: sdf file containing a single structure to align to
    :param final_sdf_path: path to write the sdf file containing the single best aligned structure
    :return: path to sdf file containing single best aligned structure
    """
    if os.path.exists(final_sdf_path):
        return final_sdf_path

    template_mol2 = convert_sdf_to_mol2(template_sdf)
    lsalign_dir = os.path.join(os.path.dirname(query_sdf), "lsalign")
    os.makedirs(lsalign_dir, exist_ok=True)

    query_confs = [conf for conf in Chem.SDMolSupplier(query_sdf)]
    query_conf_paths = []
    for i, conf in enumerate(query_confs):
        # Write each conformer to it's own file
        conf_sdf = os.path.join(lsalign_dir, f"conf_{i}.sdf")
        writer = Chem.SDWriter(conf_sdf)
        writer.write(conf)
        writer.close()
        query_conf_paths.append(conf_sdf)

    aligned_conf_paths = []

    # Run each conformer in parallel *theoretically...
    with ProcessPoolExecutor() as executor:
        futures = [
            executor.submit(align_conf, conf, i, lsalign_dir, template_mol2)
            for i, conf in enumerate(query_conf_paths[:4])
        ]
        for future in as_completed(futures):
            aligned_path = future.result()

            if aligned_path:
                aligned_conf_paths.append(aligned_path)

    aligned_confs = []
    for path in aligned_conf_paths:
        aligned_confs.append(Chem.SDMolSupplier(path)[0])

    sorted_confs = sorted(
        aligned_confs, key=lambda x: float(x.GetProp("LSAlign_PCScore")), reverse=True
    )
    final_mol = Chem.AddHs(sorted_confs[0], addCoords=True)
    writer = Chem.SDWriter(final_sdf_path)
    writer.write(final_mol)
    writer.close()

    # Delete intermediary files
    shutil.rmtree(lsalign_dir)

    return final_sdf_path
